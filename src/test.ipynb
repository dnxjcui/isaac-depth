{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth-Aware Isaac Model Test\n",
    "\n",
    "Minimal test for model loading and basic inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / \"perceptron\" / \"huggingface\"))\n",
    "sys.path.insert(0, str(project_root / \"Depth-Anything-V2\"))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import depth-aware Isaac\n",
    "from src.depth_isaac import (\n",
    "    IsaacConfig,\n",
    "    IsaacForConditionalGeneration,\n",
    "    IsaacProcessor,\n",
    ")\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = project_root / \"isaac_model\"\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "# Load config\n",
    "config = IsaacConfig.from_pretrained(str(model_path))\n",
    "\n",
    "# Optional: Set depth checkpoint path if available\n",
    "depth_checkpoint = project_root / \"depth_anything_v2_vitl.pth\"\n",
    "if depth_checkpoint.exists():\n",
    "    config.depth_checkpoint_path = str(depth_checkpoint)\n",
    "    config.use_depth = True\n",
    "    print(f\"✓ Depth checkpoint found, enabling depth\")\n",
    "else:\n",
    "    config.use_depth = False\n",
    "    print(f\"⚠ Depth checkpoint not found, depth disabled\")\n",
    "\n",
    "# Load processor\n",
    "processor = IsaacProcessor.from_pretrained(str(model_path))\n",
    "\n",
    "# Load model\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "model = IsaacForConditionalGeneration.from_pretrained(\n",
    "    str(model_path),\n",
    "    torch_dtype=dtype,\n",
    "    device_map=\"auto\" if device == \"cuda\" else None,\n",
    ")\n",
    "\n",
    "print(\"✓ Model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Text Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test text-only inference\n",
    "text = \"Hello, how are you?\"\n",
    "inputs = processor(text, return_tensors=\"pt\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    inputs = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "              for k, v in inputs.items()}\n",
    "\n",
    "print(f\"Input: {text}\")\n",
    "print(f\"Input IDs shape: {inputs['input_ids'].shape}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "print(f\"✓ Text inference successful\")\n",
    "print(f\"  Logits shape: {outputs.logits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Vision + Text Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test vision + text inference\n",
    "dummy_image = Image.fromarray(\n",
    "    np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
    ")\n",
    "\n",
    "text_with_image = f\"Describe this image: {processor.vision_token}\"\n",
    "inputs = processor(text_with_image, images=dummy_image, return_tensors=\"pt\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    inputs = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "              for k, v in inputs.items()}\n",
    "\n",
    "print(f\"Input: {text_with_image}\")\n",
    "print(f\"Image size: {dummy_image.size}\")\n",
    "print(f\"Input IDs shape: {inputs['input_ids'].shape}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "print(f\"✓ Vision + text inference successful\")\n",
    "print(f\"  Logits shape: {outputs.logits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isaac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
